{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chatbot(prompt, temperature=0.7, max_tokens=150, top_p=1, frequency_penalty=0, \n",
    "            presence_penalty=0, n=1, stop=None):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "            temperature=0.2,  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "            max_tokens=200,  # Limits response length\n",
    "            top_p=1,  # Nucleus sampling (lower = focused, higher = diverse)\n",
    "            frequency_penalty=0,  # Reduces word repetition (-2.0 to 2.0)\n",
    "            presence_penalty=1,  # Encourages new topics/words (-2.0 to 2.0)\n",
    "            n=1,  # Number of responses generated\n",
    "            stop=None  # Stops at specified words/phrases (e.g., stop=[\"END\"])\n",
    "                \n",
    "    )\n",
    "    response_dict = response.model_dump()\n",
    "    # ic(response_dict)\n",
    "    response_message = response_dict[\"choices\"][0][\"message\"][\"content\"]  # lookup the dict\n",
    "    return response_message\n",
    "\n",
    "\n",
    "\n",
    "topic = \"technology\"\n",
    "user_input = input(f\"Ask me anything about {topic}: \")\n",
    "response = chatbot(\n",
    "    user_input, \n",
    "    temperature=0.7, \n",
    "    max_tokens=150, \n",
    "    top_p=1, \n",
    "    frequency_penalty=0, \n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nChatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter            | Purpose                                   | Recommended Values |\n",
    "|----------------------|-----------------------------------------|--------------------|\n",
    "| `temperature`       | Controls randomness (0 = deterministic, 1 = creative) | `0.2 - 0.8`       |\n",
    "| `max_tokens`       | Limits response length                   | `50 - 500`        |\n",
    "| `top_p`           | Nucleus sampling for diversity (lower = focused, higher = diverse) | `0.5 - 0.9`       |\n",
    "| `frequency_penalty` | Reduces word repetition (-2.0 to 2.0)   | `0.0 - 1.5`       |\n",
    "| `presence_penalty`  | Encourages new words/topics (-2.0 to 2.0) | `0.0 - 1.5`       |\n",
    "| `n`                | Number of responses generated            | `1 - 3`           |\n",
    "| `stop`             | Stops response at specified words        | Custom words      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def summarybot(prompt, temperature=0.7, max_tokens=150, top_p=1, frequency_penalty=0, \n",
    "            presence_penalty=0, n=1, stop=None):\n",
    "    \"\"\"\n",
    "    Function to summarize a given text using OpenAI GPT API\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that summarizes text.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "            temperature=0.2,  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "            max_tokens=200,  # Limits response length\n",
    "            top_p=1,  # Nucleus sampling (lower = focused, higher = diverse)\n",
    "            frequency_penalty=0,  # Reduces word repetition (-2.0 to 2.0)\n",
    "            presence_penalty=1,  # Encourages new topics/words (-2.0 to 2.0)\n",
    "            n=1,  # Number of responses generated\n",
    "            stop=None  # Stops at specified words/phrases (e.g., stop=[\"END\"])\n",
    "                \n",
    "    )\n",
    "    response_dict = response.model_dump()\n",
    "    # ic(response_dict)\n",
    "    response_message = response_dict[\"choices\"][0][\"message\"][\"content\"]  # lookup the dict\n",
    "    return response_message\n",
    "\n",
    "\n",
    "\n",
    "text_input = r'../a_modest_proposal.txt'\n",
    "\n",
    "try:\n",
    "    with open(text_input, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_input = file.read()\n",
    "\n",
    "    summary = summarybot(text_input)\n",
    "    print(\"\\nSummary:\\n\", summary)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def translationbot(prompt, temperature=0.7, max_tokens=150, top_p=1, frequency_penalty=0, \n",
    "            presence_penalty=0, n=1, stop=None):\n",
    "    \"\"\"\n",
    "    Function to summarize a given text using OpenAI GPT API\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that translates text to french.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "            temperature=0.2,  # Controls randomness (0 = deterministic, 1 = more creative)\n",
    "            max_tokens=500,  # Limits response length\n",
    "            top_p=1,  # Nucleus sampling (lower = focused, higher = diverse)\n",
    "            frequency_penalty=0,  # Reduces word repetition (-2.0 to 2.0)\n",
    "            presence_penalty=0,  # Encourages new topics/words (-2.0 to 2.0)\n",
    "            n=1,  # Number of responses generated\n",
    "            stop=None  # Stops at specified words/phrases (e.g., stop=[\"END\"])\n",
    "                \n",
    "    )\n",
    "    response_dict = response.model_dump()\n",
    "    # ic(response_dict)\n",
    "    response_message = response_dict[\"choices\"][0][\"message\"][\"content\"]  # lookup the dict\n",
    "    return response_message\n",
    "\n",
    "\n",
    "\n",
    "text_input = r'../a_modest_proposal.txt'\n",
    "\n",
    "try:\n",
    "    with open(text_input, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_input = file.read()\n",
    "\n",
    "    translation = translationbot(text_input)\n",
    "    print(\"\\ntranslation:\\n\", translation)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
