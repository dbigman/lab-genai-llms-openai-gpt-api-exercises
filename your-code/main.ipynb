{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB GenAI - LLMs - OpenAI GPT API Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a simple chatbot that can answer basic questions about a given topic (e.g., history, technology).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "def chatbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API and return three different responses:\n",
    "    1. Controlled, Predictable Output (Low Creativity)\n",
    "    2. Balanced Output (Medium Creativity)\n",
    "    3. Maximum Creativity, Long-Winded Output (High Creativity)\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity\", \"temperature\": 0.9, \"max_tokens\": 300, \"top_p\": 1.0, \"frequency_penalty\": 1.5, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=setting[\"temperature\"],\n",
    "            max_tokens=setting[\"max_tokens\"],\n",
    "            top_p=setting[\"top_p\"],\n",
    "            frequency_penalty=setting[\"frequency_penalty\"],\n",
    "            presence_penalty=setting[\"presence_penalty\"],\n",
    "            n=1,\n",
    "            stop=None\n",
    "            # stop=[\"\\n\\n\", \".\"]\n",
    "        )\n",
    "        \n",
    "        response_dict = response.model_dump()\n",
    "        responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Convert responses into a Pandas DataFrame\n",
    "    df = pd.DataFrame([responses])\n",
    "    return df\n",
    "\n",
    "user_input = input(f\"Ask me anything about the universe\")\n",
    "response_df = chatbot(user_input)\n",
    "# ic(response)\n",
    "\n",
    "print(tabulate(response_df.T, headers='keys', tablefmt='grid'))\n",
    "\n",
    "# def print_df(df):\n",
    "#     print(tabulate(df, headers='keys', tablefmt='grid'))\n",
    "\n",
    "\n",
    "# print(\"\\nChatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter            | Purpose                                   | Recommended Values |\n",
    "|----------------------|-----------------------------------------|--------------------|\n",
    "| `temperature`       | Controls randomness (0 = deterministic, 1 = creative) | `0.2 - 0.8`       |\n",
    "| `max_tokens`       | Limits response length                   | `50 - 500`        |\n",
    "| `top_p`           | Nucleus sampling for diversity (lower = focused, higher = diverse) | `0.5 - 0.9`       |\n",
    "| `frequency_penalty` | Reduces word repetition (-2.0 to 2.0)   | `0.0 - 1.5`       |\n",
    "| `presence_penalty`  | Encourages new words/topics (-2.0 to 2.0) | `0.0 - 1.5`       |\n",
    "| `n`                | Number of responses generated            | `1 - 3`           |\n",
    "| `stop`             | Stops response at specified words        | Custom words      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Write a script that takes a long text input and summarizes it into a few sentences.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def summarybot(prompt):\n",
    "    \"\"\"\n",
    "    Function to summarize a given text using OpenAI GPT API with three different creativity levels.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity\", \"temperature\": 0.9, \"max_tokens\": 500, \"top_p\": 1.0, \"frequency_penalty\": 1.5, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that summarizes text.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=setting[\"temperature\"],\n",
    "            max_tokens=setting[\"max_tokens\"],\n",
    "            top_p=setting[\"top_p\"],\n",
    "            frequency_penalty=setting[\"frequency_penalty\"],\n",
    "            presence_penalty=setting[\"presence_penalty\"],\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "        \n",
    "        response_dict = response.model_dump()\n",
    "        responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Convert responses into a Pandas DataFrame\n",
    "    df = pd.DataFrame([responses])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "text_input = r'../a_modest_proposal.txt'\n",
    "\n",
    "try:\n",
    "    with open(text_input, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_input = file.read()\n",
    "\n",
    "    summary_df = summarybot(text_input)\n",
    "    print(tabulate(summary_df.T, headers='keys', tablefmt='grid'))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Develop a tool that translates text from one language to another using the API.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from icecream import ic\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "def translationbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to translate a given text to French using OpenAI GPT API with three different creativity levels.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity\", \"temperature\": 1.0, \"max_tokens\": 500, \"top_p\": 1.0, \"frequency_penalty\": -2.0, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that translates text to French.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=setting[\"temperature\"],\n",
    "            max_tokens=setting[\"max_tokens\"],\n",
    "            top_p=setting[\"top_p\"],\n",
    "            frequency_penalty=setting[\"frequency_penalty\"],\n",
    "            presence_penalty=setting[\"presence_penalty\"],\n",
    "            n=1,\n",
    "            stop=None\n",
    "        )\n",
    "        \n",
    "        response_dict = response.model_dump()\n",
    "        responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    # Convert responses into a Pandas DataFrame\n",
    "    df = pd.DataFrame([responses])\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "text_input = r'../a_modest_proposal.txt'\n",
    "\n",
    "try:\n",
    "    with open(text_input, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_input = file.read()\n",
    "\n",
    "    translation_df = translationbot(text_input)\n",
    "    #print(\"\\ntranslation:\\n\", translation)\n",
    "    print(tabulate(translation_df.T, headers='keys', tablefmt='grid'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool that determines the sentiment of a given text (positive, negative, neutral).  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=\"sentimentbot.log\", level=logging.INFO, \n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def sentimentbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to determine the sentiment of a given text (positive, negative, neutral) using OpenAI GPT API with three different creativity levels.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity\", \"temperature\": 1.0, \"max_tokens\": 500, \"top_p\": 1.0, \"frequency_penalty\": -2.0, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a sentiment analysis analyzer that determines the sentiment of a given text (positive, negative, neutral). Answer only 'POSITIVE', 'NEGATIVE' or 'NEUTRAL'.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=setting[\"temperature\"],\n",
    "                max_tokens=setting[\"max_tokens\"],\n",
    "                top_p=setting[\"top_p\"],\n",
    "                frequency_penalty=setting[\"frequency_penalty\"],\n",
    "                presence_penalty=setting[\"presence_penalty\"],\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            response_dict = response.model_dump()\n",
    "            responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            logging.info(f\"Sentiment analysis successful for setting: {setting['name']}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in sentimentbot for setting {setting['name']}: {e}\")\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def sentimentbot_ds(prompt, client):\n",
    "    \"\"\"\n",
    "    Function to determine sentiment using DeepSeek API with three different creativity levels.\n",
    "    \"\"\"\n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity (DS)\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity (DS)\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity (DS)\", \"temperature\": 1.0, \"max_tokens\": 500, \"top_p\": 1.0, \"frequency_penalty\": -2.0, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a sentiment analysis analyzer that determines the sentiment of a given text (positive, negative, neutral). Answer only 'POSITIVE', 'NEGATIVE' or 'NEUTRAL'.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=setting[\"temperature\"],\n",
    "                max_tokens=setting[\"max_tokens\"],\n",
    "                top_p=setting[\"top_p\"],\n",
    "                frequency_penalty=setting[\"frequency_penalty\"],\n",
    "                presence_penalty=setting[\"presence_penalty\"],\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            response_dict = response.model_dump()\n",
    "            responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            logging.info(f\"DeepSeek sentiment analysis successful for setting: {setting['name']}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in sentimentbot_ds for setting {setting['name']}: {e}\")\n",
    "    \n",
    "    return responses\n",
    "\n",
    "column_name = 'reviews.text'\n",
    "test_path = r'../sentimentbot_test.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(test_path)\n",
    "    logging.info(\"CSV file successfully loaded.\")\n",
    "\n",
    "    if column_name not in df.columns:\n",
    "        logging.error(f\"Error: Column '{column_name}' not found in the CSV.\")\n",
    "    else:\n",
    "        sentiment_results = df[column_name].astype(str).apply(sentimentbot)\n",
    "        sentiment_df = pd.DataFrame(sentiment_results.tolist())\n",
    "        df = df.join(sentiment_df)\n",
    "        logging.info(\"OpenAI sentiment analysis completed.\")\n",
    "        \n",
    "        deepseek_client = openai.OpenAI(api_key=\"DEEPSEEK_API_KEY\", base_url=\"DEEPSEEK_ENDPOINT\")\n",
    "        sentiment_results_ds = df[column_name].astype(str).apply(lambda x: sentimentbot_ds(x, deepseek_client))\n",
    "        sentiment_ds_df = pd.DataFrame(sentiment_results_ds.tolist())\n",
    "        df = df.join(sentiment_ds_df)\n",
    "        logging.info(\"DeepSeek sentiment analysis completed.\")\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_path = f\"sentimentbot_test_{timestamp}.csv\"\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logging.info(f\"Sentiment analysis results saved to: {output_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error processing the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Create a text completion application that generates text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename=\"textcompletionbot.log\", level=logging.INFO, \n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def textcompletionbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to generate text completions using OpenAI GPT API with three different creativity levels.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    settings = [\n",
    "        {\"name\": \"Low Creativity\", \"temperature\": 0.0, \"max_tokens\": 100, \"top_p\": 0.1, \"frequency_penalty\": 2.0, \"presence_penalty\": -2.0},\n",
    "        {\"name\": \"Medium Creativity\", \"temperature\": 0.7, \"max_tokens\": 200, \"top_p\": 0.8, \"frequency_penalty\": 0, \"presence_penalty\": 0},\n",
    "        {\"name\": \"High Creativity\", \"temperature\": 1.0, \"max_tokens\": 500, \"top_p\": 1.0, \"frequency_penalty\": -2.0, \"presence_penalty\": 2.0},\n",
    "    ]\n",
    "    \n",
    "    responses = {}\n",
    "    \n",
    "    for setting in settings:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a text completion application that generates text based on an initial prompt.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=setting[\"temperature\"],\n",
    "                max_tokens=setting[\"max_tokens\"],\n",
    "                top_p=setting[\"top_p\"],\n",
    "                frequency_penalty=setting[\"frequency_penalty\"],\n",
    "                presence_penalty=setting[\"presence_penalty\"],\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            response_dict = response.model_dump()\n",
    "            responses[setting[\"name\"]] = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "            logging.info(f\"Text completion successful for setting: {setting['name']}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in textcompletionbot for setting {setting['name']}: {e}\")\n",
    "    \n",
    "    return responses\n",
    "\n",
    "# Example execution\n",
    "topic = \"Hungary\"\n",
    "user_input = 'Hungary is a great place to visit.'\n",
    "\n",
    "try:\n",
    "    response_df = pd.DataFrame([textcompletionbot(user_input)])\n",
    "    logging.info(\"Text completion executed successfully.\")\n",
    "    print(response_df)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error executing text completion bot: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS: Google Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Conversation\n",
    "**Exercise:** Create a basic chatbot using Google Vertex AI to answer questions about a given topic.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `stop`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key and credentials\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "credentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY is not set in the environment variables.\")\n",
    "if not credentials_path:\n",
    "    raise ValueError(\"GOOGLE_APPLICATION_CREDENTIALS is not set in the environment variables.\")\n",
    "\n",
    "# Configure Generative AI API\n",
    "config = generation_config = {\n",
    "    \"temperature\": 0.7,  \n",
    "    \"max_output_tokens\": 256, \n",
    "    \"top_p\": 0.9,  \n",
    "    \"frequency_penalty\": 0.0,  \n",
    "    \"presence_penalty\": 0.0    \n",
    "}\n",
    "\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# Load the pre-trained chat model\n",
    "chat_model = genai.GenerativeModel(\"gemini-pro\")  \n",
    "\n",
    "print(\"Chatbot is ready! Type 'exit' or 'quit' to stop.\\n\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    response = chat_model.generate_content(user_input, generation_config=config)\n",
    "    print(\"Bot:\", response.text, \"\\n\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error executing bot: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "**Exercise:** Develop a script that summarizes long text inputs using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `best_of`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key and credentials\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "credentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY is not set in the environment variables.\")\n",
    "if not credentials_path:\n",
    "    raise ValueError(\"GOOGLE_APPLICATION_CREDENTIALS is not set in the environment variables.\")\n",
    "\n",
    "# Configure Generative AI API\n",
    "config = generation_config = {\n",
    "    \"temperature\": 0.7,  \n",
    "    \"max_output_tokens\": 256, \n",
    "    \"top_p\": 0.9,  \n",
    "    \"frequency_penalty\": 0.0,  \n",
    "    \"presence_penalty\": 0.0    \n",
    "}\n",
    "\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# Load the pre-trained chat model\n",
    "chat_model = genai.GenerativeModel(\"gemini-pro\")  \n",
    "\n",
    "# Open and read the contents of the file\n",
    "with open(r'../the_arkansaw_bear.txt', 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "\n",
    "# Configure Generative AI API\n",
    "config = generation_config = {\n",
    "    \"temperature\": 0.7,  \n",
    "    \"max_output_tokens\": 1000, \n",
    "    \"top_p\": 0.9,  \n",
    "    \"frequency_penalty\": 0.0,  \n",
    "    \"presence_penalty\": 0.0    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    user_input = 'summarize this text: ' + text_content\n",
    "    response = chat_model.generate_content(user_input, generation_config=config)\n",
    "    print(\"Bot:\", response.text, \"\\n\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error executing bot: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Translation\n",
    "**Exercise:** Create a tool that translates text from one language to another using Google Vertex AI.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `echo`, `logit_bias`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key and credentials\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "credentials_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "\n",
    "if not google_api_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY is not set in the environment variables.\")\n",
    "if not credentials_path:\n",
    "    raise ValueError(\"GOOGLE_APPLICATION_CREDENTIALS is not set in the environment variables.\")\n",
    "\n",
    "# Configure Generative AI API\n",
    "config = generation_config = {\n",
    "    \"temperature\": 0.7,  \n",
    "    \"max_output_tokens\": 256, \n",
    "    \"top_p\": 0.9,  \n",
    "    \"frequency_penalty\": 0.0,  \n",
    "    \"presence_penalty\": 0.0    \n",
    "}\n",
    "\n",
    "\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# Load the pre-trained chat model\n",
    "chat_model = genai.GenerativeModel(\"gemini-pro\")  \n",
    "\n",
    "# Open and read the contents of the file\n",
    "with open(r'../the_arkansaw_bear.txt', 'r', encoding='utf-8') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "\n",
    "# Configure Generative AI API\n",
    "config = generation_config = {\n",
    "    \"temperature\": 0.7,  \n",
    "    \"max_output_tokens\": 20000, \n",
    "    \"top_p\": 0.9,  \n",
    "    \"frequency_penalty\": 0.0,  \n",
    "    \"presence_penalty\": 0.0    \n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    user_input = 'translate this text to spanish: ' + text_content\n",
    "    response = chat_model.generate_content(user_input, generation_config=config)\n",
    "    print(\"Bot:\", response.text)\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error executing bot: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis\n",
    "**Exercise:** Implement a sentiment analysis tool using Google Vertex AI to determine the sentiment of a given text.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `n`, `logprobs`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Text Completion\n",
    "**Exercise:** Develop a text completion application using Google Vertex AI to generate text based on an initial prompt.  \n",
    "**Parameters to explore:** `temperature`, `max_output_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `stop`, `best_of`.\n",
    "\n",
    "Comment what happen when you change the parameters \n",
    "(read documentation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
